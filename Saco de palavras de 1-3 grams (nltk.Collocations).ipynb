{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saco de palavras de 1-3 grams (usando nltk.Collocations)\n",
    "\n",
    "## Solução:\n",
    "1. Criar uma lista de \"stopwords\" adequada para termos de \"n\" palavras e outra para onegrams;\n",
    "2. Gerar uma lista de \"tokens\" removendo pontuação e as \"stopwords\";\n",
    "3. Criar um conjunto de amostras de discursos para gerar uma lista de bigrams filtrados pelo score PMI(Pointwise mutual information).\n",
    "4. Definir um limite de ocorrências mínimo;\n",
    "5. Criar uma nova lista de bigrams do conjunto de discursos com quantidade de ocorrências maior que o limite;\n",
    "6. Filtrar da nova lista de bigrams apenas os que aparecem na lista de bigrams definidas com o score PMI;\n",
    "7. Remover as bigrams filtradas do nosso corpus;\n",
    "8. Criar uma lista de trigrams com quantidade de ocorrências maior que o limite;\n",
    "    * Deve-se observar que os trigrams que tem como subconjunto um bigram, não irá aparecer nesta lista.\n",
    "9. Remover os trigrams filtrados do nosso corpus;\n",
    "10. Criar uma lista de onegrams com quantidade de ocorrências maior que o limite;\n",
    "    * Deve-se observar que os onegrams são um subconjunto dos bigrams ou trigrams irão aparecer nesta lista desde que não estejam associadas as mesmas.\n",
    "11. São somados os 3 grupos e retorna a lista de termos mais frequentes.\n",
    "\n",
    "## Problemas:\n",
    "1. Termos com mais de 3 palavras são exibidos nos trigrams;\n",
    "2. Subconjuntos de trigrams que possuem um score pmi alto na lista de bigram são descartados e mostrados como bigrams. \n",
    "3. Bigrams criados recentementos com palavras de uso universal apresentam um score baixo, podendo não aparecer na lista de filtro.\n",
    "\n",
    "## Conclusões:\n",
    "1. Os termos apresentados como resultado fazem sentido.\n",
    "2. É mais acertivo quando possui uma grande base de discursos.\n",
    "3. Termos recente com mais de uma palavra podem não aparecer no resultado por possuir um score baixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics.association import QuadgramAssocMeasures\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Endereço da API dos discursos\n",
    "BABEL_API_URL = 'https://babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=1'\n",
    "\n",
    "# Pegando os 200 primeiros discursos da API do Babel\n",
    "speeches = []\n",
    "data = requests.get(BABEL_API_URL).json()['results']\n",
    "for i in range(2, 100):\n",
    "    data += requests.get(BABEL_API_URL + '&page=%s' % i).json()['results']\n",
    "    \n",
    "for speech in data:\n",
    "    for attr in speech['attrs']:\n",
    "        if attr['field'] == 'original':\n",
    "            speeches.append(attr['value'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando a lista de stopwords em português\n",
    "EXTRA_STOPWORDS = [\n",
    "    'sr.', 'nesse', 'deputados', '``', \"''\", 'empresa', 'trabalhadores', 'tema', 'brasil', 'brasileiro',\n",
    "    'brasileira', 'sociedade', 'grandes', 'meios', 'principal', 'deputada', 'nesta', 'valor', 'reais',\n",
    "    'representante', 'brasileiros', 'necessidade', 'quero', 'ser', 'geral', 'todo', 'toda', 'estar',\n",
    "    'ter', 'parlamentares', 'região', 'forma', 'parte', 'disso', 'debate', 'entregar', 'nessa', 'nome',\n",
    "    'vez', 'quer', 'primeira', 'soberania', 'justamente', 'ponto', 'presentes', 'faz', 'futuro', 'podem',\n",
    "    'maneira', 'falar', 'interesses', 'caso', 'espaço', 'entrega', 'deste', 'mesma', 'negócio', 'existe',\n",
    "    'avançar', 'ano', 'diz', 'próprios', 'criação', 'própria', 'dizendo', 'trazer', 'preocupação', 'ali',\n",
    "    'ficar', 'desse', 'importância', 'senhor', 'queremos', 'poderia', 'ir', 'próprio', 'área', 'segundo',\n",
    "    'acontece', 'sei', 'sabem', 'comum', 'mim', 'tratar', 'obrigação', 'falando', 'discurso', 'muitas',\n",
    "    'acabou', 'falou', 'outro', 'capacidade', 'força','querem', 'significa', 'serviço', 'dados', 'tentar',\n",
    "    'ninguém', 'gente', 'ideia', 'deputadas', 'dentro', 'fazendo', 'mão', 'época', 'uso', 'fiz', 'último',\n",
    "    'nenhum', 'números', 'alguma', 'acreditamos', 'achamos', 'pagar', 'paga', 'conjunto', 'contentam',\n",
    "    'lacunas', 'esperamos', 'digo', 'sente', 'logo', 'pesquisar', 'principais', 'mudar', 'sequer', 'pagou',\n",
    "    'pagando', 'traz', 'desafio', 'concreto', 'atende', 'tendo', 'aberto', 'curto', 'recebe', 'receber',\n",
    "    'décadas', 'minutos', 'horas', 'segundos', 'motivo', 'posso', 'dando', 'entra', 'volto', 'construir',\n",
    "    'algumas', 'passar', 'muita', 'nisso', 'deveria', 'dá', 'construir', 'muito', 'longo', 'muitas', 'outras',\n",
    "    'existem', 'conseguimos', 'precisamos', 'feita', 'mencionou', 'falei', 'cujo', 'hora', 'dizia', 'venha',\n",
    "    'conseguindo', 'conseguir', 'votar', 'alguém', 'somente', 'todas', 'fizemos', 'citar', 'saiba', 'boa',\n",
    "    'deveriam', 'acontecendo', 'algo', 'apresentei', 'sabemos', 'outra', 'junto', 'daqui', 'aconteceu',\n",
    "    'haver', 'sinto', 'preciso', 'muitos', 'minimamente', 'amanhã', 'ontem', 'partir', 'objetivo', 'opinião',\n",
    "    'vivemos', 'discutindo', 'agradecemos', 'utilizados', 'contra', 'dona', 'falta', 'possa', 'manhã', 'novas',\n",
    "    'após', 'pessoas', 'fundamental', 'desses', 'devido', 'item', 'século', 'domingo', 'sábado',\n",
    "    'presidente', ',', '.', '...', 'é', 'questão', 'art', 'ordem', 'v.exa', ':', 'governo', 'sr', 'agência',\n",
    "    'aqui', 'vai', 'artigo', '§', 'neste', 'vamos', 'agora', \"''\", 'fazer', 'mesa', 'ainda', 'porque', 'trata',\n",
    "    'estrutura', 'sobre', 'então', 'todos', 'obstrução', 'votação', 'presença', 'deputados', 'vou', 'brasil',\n",
    "    'discutir', 'vigência', 'colocar', 'regimento', 'momento', ';', 'dois', 'dessa', 'medida', 'proposta',\n",
    "    'casa', 'matéria', 'queria', 'assim', 'possamos', 'microfone', 'certeza', 'hoje', 'profissional', 'deixar',\n",
    "    'provisória', 'ora', 'base', 'importante', 'veto', 'fala', '!', 'aumento', 'inciso', 'sra.', 'talvez',\n",
    "    'cima', 'servir', 'nunca', 'dias', 'deus', 'dei', 'entendemos', 'chega', 'possam', 'entendo', 'poderá',\n",
    "    'celeridade', 'tirar', 'mista', 'fechou-se', 'lado', 'lido', 'repassado', 'demais', 'venho', 'marcar',\n",
    "    'xiii', 'diálogo', 'podemos', 'apenas', 'poder', 'efeitos', 'pode', 'acordo', 'solicitação',\n",
    "    'reflexão', '?', 'ausência', 'aprovada', 'lideranças', 'dizer', 'portanto', 'peço', 'recolher',\n",
    "    'prática', 'pois', 'milhões', 'bilhões', 'melhoria', 'atividade', 'claro', 'saber', 'dar',\n",
    "    'avanço', 'condições', 'desastre', 'especialmente', 'exatamente', 'política', 'vezes', 'fazê-lo', 'têm',\n",
    "    'derrubar', 'precisa', 'custo', 'necessária', 'cláusula', 'proposição', '-', 'palavra', 'tempo', 'segundos',\n",
    "    'fez', 'necessário', 'zero', 'interesse', 'srs', 'sr', 'sras', 'sra', 'deputado', 'presidente', 'é', 'nº',\n",
    "    's.a.', 'v.exa.', 'v.exa', '#', 'anos', 'º', 'exa', 'mesa', 'legislatura', 'sessão', 'maioria', 'seguinte',\n",
    "    'mandato', 'bilhões', 'quilômetros', 'ª', 'parabéns', 'membros', 'convido', 'usual', 'biênio',\n",
    "    'brasil', 'palavra', 'discussão', 'período', 'início', 'pronunciamento', 'suplente', 'atividade', 'ação',\n",
    "    'ações', 'daqueles', 'diferenças', 'pasta', 'milhares', 'srªs', 'emenda', 'àqueles', 'tamanha', 'mês',\n",
    "    'capaz', 'km', 'modelo', 'tarefas', 'colegas', 'programa', 'voz', 'pronunciamento',\n",
    "    'casa', 'sessão', 'deliberativa', 'solene', 'ordinária', 'extraordinária', 'encaminhado', 'orador',\n",
    "    'divulgar', 'deputado', 'parlamentar', 'projeto', 'proposta', 'requerimento', 'destaque',\n",
    "    'veto', 'câmara', 'senado', 'congresso', 'país', 'estado', 'brasil', 'lei', 'novo', 'nova',\n",
    "    'política', 'povo', 'voto', 'partido', 'liderança', 'bancada', 'bloco', 'líder', 'lider', 'frente',\n",
    "    'governo', 'oposição', 'presença', 'presente', 'passado', 'ausência', 'ausencia', 'ausente', 'obstrução',\n",
    "    'registrar', 'aprovar', 'rejeitar', 'rejeição', 'sabe', 'matéria', 'materia', 'questão', 'ordem', 'emenda',\n",
    "    'sistema', 'processo', 'legislativo', 'plenário', 'pedir', 'peço', 'comissão', 'especial', 'permanente',\n",
    "    'apresentar', 'encaminhar', 'encaminho', 'orientar', 'liberar', 'apoiar', 'situação', 'fato', 'revisão',\n",
    "    'tempo', 'pauta', 'discutir', 'discussão', 'debater', 'retirar', 'atender', 'colegas', 'autor', 'texto',\n",
    "    'medida', 'união', 'república', 'audiência', 'audiencia', 'público', 'publico', 'reunião', 'agradecer',\n",
    "    'solicitar', 'assistir', 'contrário', 'favorável', 'pessoa', 'comemorar', 'ato', 'momento', 'diretora',\n",
    "    'possível', 'atenção', 'agradeço', 'naquele', 'necessárias', 'presidenta', 'compromisso', 'geradas',\n",
    "    'primeiro', 'simplesmente', 'ideal', 'argumento', 'i', 'válido', 'envolvidos', 'nesse', 'aspecto',\n",
    "    'existentes', 'normativo', 'irá', 'nada', 'melhor', 'esperarmos', 'pouco', 'resolvermos', 'problema',\n",
    "    'postura', 'faltas', 'declara', '%', 'dia', 'obrigado', 'agradeço', 'agradecido', 'população',\n",
    "    'maior', 'cada', 'bem', 'mundo', 'desta', 'mil', 'sendo', 'outros', '$', '!', '@', '#', '&', '(', ')',\n",
    "    'r', 'sempre', 'além', 'semana', 'relação', 'onde', 'meio', 'inclusive', 'lá', 'vem', 'menos', 'menor',\n",
    "    'qualquer', 'desde', 'ontem', 'hoje', 'exemplos', 'exemplo', 'tão', 'fim', 'janeiro', 'fevereiro', 'março',\n",
    "    'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro', 'alguns',\n",
    "    'durante', 'gostaria', 'três', 'conta', 'feito', 'através', 'antes', 'depois', 'verdade', 'bom', 'quase',\n",
    "    'setor', 'aí', 'disse', 'principalmente', 'final', 'vão', 'coisa', 'ver', 'sentido', 'vários',\n",
    "    'nenhuma', 'quanto', 'infelizmente', 'felizmente', 'número', 'duas', 'dois', 'tanto', 'acho', 'achar',\n",
    "    'enquanto', 'deve', 'apelo', 'papel', 'últimos', 'faço', 'fazer', 'garantir', 'garantia', 'fica',\n",
    "    'obrigado..', 'assunto', 'sido', 'vir', 'incrementar', 'central', 'aproximado', 'aproximadamente',\n",
    "    'hipotética', 'hipotese', 'hipótese', 'superiores', 'entende', 'pedido', 'oradora', 'tal', 'v.exas',\n",
    "    'favor', 'vota', 'nº', 'srª', 'vista', 'sim', 'dito', 'tudo', 'obrigado', 'º', 'profundamente', 'custódio',\n",
    "    'divulgado', 'características', 'perfeito', 'começarmos', 'nomes', 'amigo', 'possibilidade', 'mensagem',\n",
    "    'come', 'parabenizar', 'começar', 'hs', 'atendimento', 'povos', '¯', 'ocorreu', 'entanto', 'diante',\n",
    "    'defender', 'dr.', '“', '”', '•', 'v.', './', 'és', 'senhoras', 'senhores', 'tipo', 'várias', 'gerais',\n",
    "    'quais', 'dessas', 'deu', 'havia', 'devem', 'enfim', 'apesar', 'passa', 'chegou', 'vêm', 'parece', 'u'\n",
    "]\n",
    "\n",
    "ONEGRAM_STOPWORDS = [\n",
    "    'grande', 'nacional', 'são', 'e', 'de', 'das', 'dos', 'da', 'do', 'federal', 'cedo', 'urgência', 'equipe',\n",
    "    'produtos', 'serviços', 'pequeno', 'total', 'podermos', 'consenso', 'popular', 'mérito', 'único', 'pública',\n",
    "    'escolha', 'acesso', 'pilotos', 'trabalhar', 'ministério', 'países', 'combate', 'estados', 'vida', 'cidade',\n",
    "    'municípios', 'histórico', 'defesa', 'município', 'prefeito', 'ii', 'santa', 'vereadora', 'centro',\n",
    "    'prefeitura', 'governador', 'código', 'apoio', 'exercício', 'categoria', 'campo', 'kit',\n",
    "    'ministro', 'social', 'recursos', 'direito', 'empresas', 'comunicação', 'democracia',\n",
    "    'tribuna', 'história', 'respeito', 'luta', 'oportunidade', 'dinheiro', 'públicos',\n",
    "    'civil', 'qualidade', 'políticas', 'sociais', 'registro', 'públicas', 'crescimento',\n",
    "    'responsabilidade', 'participação', 'importantes', 'gestão', 'minas', 'cidades', 'lugar',\n",
    "    'problemas', 'decisão', 'mulher', 'nobre', 'capital', 'aprovação', 'humanos', 'estadual',\n",
    "    'internacional', 'senador', 'redução', 'realmente', 'realidade', 'plano', 'partidos',\n",
    "    'conselho', 'posição', 'medidas', 'termos', 'divulgação', 'econômico', 'federais', 'fiscal',\n",
    "    'emprego', 'maiores', 'rede', 'ruas', 'regional', 'continuar', 'profissionais', 'sob',\n",
    "    'homens', 'político', 'atual', 'nação', 'meses', 'grupo', 'áreas', 'fundo', 'iniciativa',\n",
    "    'executivo', 'cerca', 'cidadão', 'prazo', 'homem', 'trabalhador', 'órgãos', 'campanha',\n",
    "    'controle', 'mínimo', 'mundial', 'dúvida', 'legislação', 'relatório', 'emendas', 'atividades',\n",
    "    'razão', 'resultado', 'instituições', 'brasileiras', 'líderes', 'última', 'secretário', 'precisam',\n",
    "    'criar', 'movimento', 'data', 'fazem', 'novos', 'casos', 'ambiente', 'administração', 'distrito',\n",
    "    'pesquisa', 'relator', 'cumprimento', 'causa', 'informações', 'evento', 'aliás', 'superior',\n",
    "    'filho', 'tarde', 'caminho', 'dificuldades', 'risco', 'publicação', 'sobretudo', 'coisas',\n",
    "    'obrigada', 'santo', 'solicito', 'cargos', 'condição', 'próximo', 'secretaria', 'formação',\n",
    "    'penal', 'forte', 'representa', 'aprovado', 'acima', 'políticos', 'setores', 'chegar',\n",
    "    'espírito', 'prefeitos', 'grave', 'solução', 'governos', 'conhecimento', 'espero',\n",
    "    'preço', 'mudança', 'instituto', 'tributária', 'amigos', 'levar', 'diversos',\n",
    "    'municipal', 'dado', 'filhos', 'proteção', 'pagamento', 'federação', 'entidades',\n",
    "    'br-', 'funcionários', 'média', 'organização', 'veículos', 'difícil', 'patrimônio',\n",
    "    'marco', 'geração', 'diversas', 'honra', 'aumentar', 'movimentos', 'idade', 'passou',\n",
    "    'inclusão', 'responsável', 'única', 'busca', 'questões', 'operação', 'participar',\n",
    "    'pequenos', 'ajudar', 'regime', 'vítimas', 'pior', 'orgulho', 'unidos', 'embora',\n",
    "    'forças', 'inteiro', 'modo', 'simples', 'programas', 'legislativa', 'caixa', 'leis',\n",
    "    'passada', 'cidadãos', 'dignidade', 'associação', 'absolutamente', 'contribuição',\n",
    "    'trata-se', 'esforço', 'representantes', 'fizeram', 'vereador', 'ficou', 'volta',\n",
    "    'quadro', 'lembrar', 'concluir', 'votos', 'classe', 'atuação', 'médio', 'receita',\n",
    "    'palavras', 'nível', 'encontro', 'milhão', 'diferente', 'local', 'estaduais',\n",
    "    'constitucional', 'recurso', 'certamente', 'nossa'\n",
    "]\n",
    "\n",
    "\n",
    "# Método para limpar texto do discurso tirando as notas do taquigrafo\n",
    "def clear_speech(text):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[OA] SRA?[\\w\\s.]+-', '', text)\n",
    "    text = re.sub(r'PRONUNCIAMENTO[\\sA-Z]+\\s', '', text)\n",
    "#     text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s[\\.\\\"]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[Vv]\\.[Ee][Xx][Aa]\\.', 'v.exa', text)\n",
    "    text = re.sub(r'[Aa][Rr][Tt]\\.', 'art', text)\n",
    "    text = re.sub(r'[Ss][Rr][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'[Ss][Rr][Aa][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def get_tokens(speeches, extra_stopwords=None):\n",
    "    \"\"\"\n",
    "    Função que retorna tokens de discursos removendo as \"stopwords\".\n",
    "    Argumentos:\n",
    "        speeches: Recebe uma lista de discursos.\n",
    "        stopwords: Recebe uma lista de palavras a serem retiradas dos textos.\n",
    "    Retorna:\n",
    "        Uma lista palavras do discurso que não estão nas \"stopwords\".\n",
    "    \"\"\"\n",
    "    special_stopwords = ['são', 'nossa']\n",
    "    stopwords = nltk_stopwords.words('portuguese') + list(punctuation) + EXTRA_STOPWORDS\n",
    "    stopwords = [word for word in stopwords if word not in special_stopwords]\n",
    "    if extra_stopwords:\n",
    "        stopwords += extra_stopwords\n",
    "    tokens = []\n",
    "    for text in speeches[:200]:\n",
    "        text = clear_speech(text)\n",
    "        tokens += [i for i in word_tokenize(text.lower(), language='portuguese') if i not in stopwords]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def clean_bigrams(bigrams):\n",
    "    \"\"\"\n",
    "    Função que cria uma lista de bigramas considerando o score pmi para comparar com a lista de bigramas\n",
    "    que recebe como argumento e retorna os bigramas filtrados.\n",
    "    Argumentos:\n",
    "        bigrams: Recebe uma lista de bigramas de maior ocorrência.\n",
    "    Retorna:\n",
    "        Uma lista de bigramas filtrados pela ocorrência e score pmi.\n",
    "    \"\"\"\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "#     tokens = get_tokens(speeches)\n",
    "    tokens = []\n",
    "    for text in speeches: # Gera bigrams com todos os discursos da base\n",
    "        text = clear_speech(text)\n",
    "        tokens += [i for i in word_tokenize(text.lower(), language='portuguese')]\n",
    "    bigram_f = BigramCollocationFinder.from_words(tokens)\n",
    "    bigram_f.apply_freq_filter(10) # filtra bigrams com frequência maior que 10\n",
    "    bigram_score_pmi = bigram_f.score_ngrams(bigram_measures.pmi)\n",
    "    bigram_list = [x[0] for x in bigram_score_pmi if x[1] >= 8.0] # Lista de bigrams com PMI > 8.0\n",
    "    bigram_result = [bigram for bigram in bigrams if bigram[0] in bigram_list]\n",
    "\n",
    "    return bigram_result\n",
    "\n",
    "\n",
    "def ngrams_by_limit(tokens, n, limit):\n",
    "    \"\"\"\n",
    "    Função que retorna uma lista de ngrams de acordo com os argumento passados.\n",
    "    Argumentos:\n",
    "        tokens: Recebe uma lista de tokens já processados pelo nltk.word_tokenize.\n",
    "        n: Recebe o número de palavras que deseja dividir o ngram.\n",
    "        limit: Recebe o limite mínimo de ocorrência.\n",
    "    Retorna:\n",
    "        Uma lista de ngrams com ocorrência maior que \"limite\" e com \"n\" palavras.\n",
    "    \"\"\"\n",
    "    ngrams_count = Counter(ngrams(tokens, n)).most_common()\n",
    "    result = [x for x in ngrams_count if x[1] >= limit]\n",
    "    return result\n",
    "\n",
    "\n",
    "def clean_tokens(tokens, bigrams=[], trigrams=[], extra_stopwords=None):\n",
    "    \"\"\"\n",
    "    Função que retorna uma lista de tokens filtradas pelos argumentos passados.\n",
    "    Argumentos:\n",
    "        tokens: Recebe uma lista de tokens já processados pelo nltk.word_tokenize.\n",
    "        bigrams: Recebe uma lista de bigramas.\n",
    "        trigrams: Recebe uma lista de trigramas.\n",
    "        extra_stopwords: Recebe uma lista de stopwords.\n",
    "    Retorna:\n",
    "        Uma lista de tokens removendo os bigramas, trigramas e stopwords passados nos argumentos.\n",
    "    \"\"\"\n",
    "    if bigrams:\n",
    "        pos_bigram = []\n",
    "        for i in range(len(tokens)-1):\n",
    "            for x, y in bigrams:\n",
    "                if tokens[i] == x and tokens[i+1] == y:\n",
    "                    pos_bigram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_bigram):\n",
    "            del tokens[pos:pos+2]\n",
    "    \n",
    "    if trigrams:\n",
    "        pos_trigram = []\n",
    "        for i in range(len(tokens)-2):\n",
    "            for x, y, z in trigrams:\n",
    "                if tokens[i] == x and tokens[i+1] == y and tokens[i+2] == z:\n",
    "                    pos_trigram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_trigram):\n",
    "            del tokens[pos:pos+3]\n",
    "    \n",
    "    if extra_stopwords:\n",
    "        new_tokens = [token for token in tokens if token not in extra_stopwords]\n",
    "    else:\n",
    "        new_tokens = tokens\n",
    "\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limite: 9\n"
     ]
    }
   ],
   "source": [
    "#Definimos os tokens\n",
    "tokens = get_tokens(speeches) # tokens de 200 discursos\n",
    "\n",
    "# Determinamos o limite de ocorrências usado no algoritmo\n",
    "limit = Counter(tokens).most_common(int(len(speeches) * 0.2))[-1][1]\n",
    "if limit < 3:\n",
    "    limit = 3\n",
    "\n",
    "print(\"Limite: %s\" % limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('rio', 'grande'), 57),\n",
       " (('segurança', 'pública'), 52),\n",
       " (('grande', 'sul'), 42),\n",
       " (('supremo', 'tribunal'), 31),\n",
       " (('tribunal', 'federal'), 30),\n",
       " (('agentes', 'comunitários'), 28),\n",
       " (('porto', 'alegre'), 26),\n",
       " (('michel', 'temer'), 22),\n",
       " (('são', 'paulo'), 22),\n",
       " (('comunitários', 'saúde'), 22),\n",
       " (('presunção', 'inocência'), 19),\n",
       " (('técnicos', 'industriais'), 16),\n",
       " (('exercício', 'ilegal'), 15),\n",
       " (('saúde', 'educação'), 14),\n",
       " (('habeas', 'corpus'), 14),\n",
       " (('santa', 'catarina'), 13),\n",
       " (('caravana', 'lula'), 13),\n",
       " (('carlos', 'manato'), 13),\n",
       " (('rodrigo', 'maia'), 12),\n",
       " (('grande', 'norte'), 11),\n",
       " (('técnicos', 'agrícolas'), 11),\n",
       " (('marielle', 'franco'), 11),\n",
       " (('polícia', 'civil'), 11),\n",
       " (('ministro', 'saúde'), 10),\n",
       " (('segunda', 'instância'), 10),\n",
       " (('são', 'francisco'), 9),\n",
       " (('taxa', 'juros'), 9),\n",
       " (('conselho', 'federal'), 9),\n",
       " (('caixa', 'econômica'), 9),\n",
       " (('econômica', 'federal'), 9),\n",
       " (('mato', 'grosso'), 9),\n",
       " (('combate', 'endemias'), 9),\n",
       " (('nossa', 'senhora'), 9),\n",
       " (('ex-presidente', 'lula'), 9),\n",
       " (('código', 'penal'), 9),\n",
       " (('agricultura', 'familiar'), 9),\n",
       " (('profissionais', 'educação'), 9),\n",
       " (('medicina', 'veterinária'), 9)]"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = ngrams_by_limit(tokens, 2, limit)\n",
    "bigrams # Bigrams de maior ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('segurança', 'pública'), 52),\n",
       " (('supremo', 'tribunal'), 31),\n",
       " (('tribunal', 'federal'), 30),\n",
       " (('agentes', 'comunitários'), 28),\n",
       " (('porto', 'alegre'), 26),\n",
       " (('michel', 'temer'), 22),\n",
       " (('são', 'paulo'), 22),\n",
       " (('técnicos', 'industriais'), 16),\n",
       " (('exercício', 'ilegal'), 15),\n",
       " (('habeas', 'corpus'), 14),\n",
       " (('santa', 'catarina'), 13),\n",
       " (('carlos', 'manato'), 13),\n",
       " (('rodrigo', 'maia'), 12),\n",
       " (('técnicos', 'agrícolas'), 11),\n",
       " (('marielle', 'franco'), 11),\n",
       " (('polícia', 'civil'), 11),\n",
       " (('segunda', 'instância'), 10),\n",
       " (('caixa', 'econômica'), 9),\n",
       " (('mato', 'grosso'), 9),\n",
       " (('nossa', 'senhora'), 9),\n",
       " (('ex-presidente', 'lula'), 9),\n",
       " (('código', 'penal'), 9),\n",
       " (('agricultura', 'familiar'), 9),\n",
       " (('medicina', 'veterinária'), 9)]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bigrams = clean_bigrams(bigrams)\n",
    "new_bigrams # Bigrams filtrados usando o PMI em 2000 discursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('rio', 'grande', 'sul'), 42), (('rio', 'grande', 'norte'), 11)]"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_bigrams = []\n",
    "\n",
    "if new_bigrams:\n",
    "    stop_bigrams = list(list(zip(*new_bigrams))[0])\n",
    "\n",
    "trigram_tokens = clean_tokens(tokens, stop_bigrams)\n",
    "trigrams = ngrams_by_limit(trigram_tokens, 3, limit)\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('saúde',), 120),\n",
       " (('violência',), 88),\n",
       " (('lula',), 88),\n",
       " (('rio',), 88),\n",
       " (('trabalho',), 79),\n",
       " (('educação',), 77),\n",
       " (('constituição',), 54),\n",
       " (('crime',), 46),\n",
       " (('caravana',), 41),\n",
       " (('segurança',), 39),\n",
       " (('polícia',), 38),\n",
       " (('obras',), 33),\n",
       " (('justiça',), 33),\n",
       " (('marielle',), 33),\n",
       " (('policiais',), 31),\n",
       " (('sergipe',), 31),\n",
       " (('ódio',), 30),\n",
       " (('obra',), 29),\n",
       " (('jovens',), 28),\n",
       " (('intervenção',), 27)]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_bigrams = stop_trigrams = []\n",
    "\n",
    "if new_bigrams:\n",
    "    stop_bigrams = list(list(zip(*new_bigrams))[0])\n",
    "if trigrams:\n",
    "    stop_trigrams = list(list(zip(*trigrams))[0])\n",
    "    \n",
    "onegram_tokens = clean_tokens(tokens, stop_bigrams, stop_trigrams, ONEGRAM_STOPWORDS)\n",
    "onegrams = ngrams_by_limit(onegram_tokens, 1, limit)\n",
    "onegrams[:20] # Os 20 primeiros onegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('saúde',), 120),\n",
       " (('violência',), 88),\n",
       " (('lula',), 88),\n",
       " (('rio',), 88),\n",
       " (('trabalho',), 79),\n",
       " (('educação',), 77),\n",
       " (('constituição',), 54),\n",
       " (('segurança', 'pública'), 52),\n",
       " (('crime',), 46),\n",
       " (('rio', 'grande', 'sul'), 42),\n",
       " (('caravana',), 41),\n",
       " (('segurança',), 39),\n",
       " (('polícia',), 38),\n",
       " (('obras',), 33),\n",
       " (('justiça',), 33),\n",
       " (('marielle',), 33),\n",
       " (('policiais',), 31),\n",
       " (('sergipe',), 31),\n",
       " (('supremo', 'tribunal'), 31),\n",
       " (('ódio',), 30)]"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tokens = onegrams + new_bigrams + trigrams\n",
    "result_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "result_tokens[:20] # Os 20 primeiros termos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
