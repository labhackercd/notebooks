{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualmente, o algoritmo se tornou popular na área de Aprendizado de Máquina (Machine Learning) para **categorizar textos baseado na frequência das palavras usadas**, e assim pode ser usado para identificar se determinado e-mail é um SPAM ou sobre qual assunto se refere determinado texto, por exemplo.\n",
    "\n",
    "Por ser muito simples e rápido, possui um desempenho relativamente maior do que outros classificadores. Além disso, o Naive Bayes só precisa de um pequeno número de dados de teste para concluir classificações com uma boa precisão.\n",
    "\n",
    "A principal característica do algoritmo, e também o motivo de receber “naive” (ingênuo) no nome, é que **ele desconsidera completamente a correlação entre as variáveis (features)**. Ou seja, se determinada fruta é considerada uma “Maçã” se ela for “Vermelha”, “Redonda” e possui “aproximadamente 10cm de diâmetro”, o algoritmo não vai levar em consideração a correlação entre esses fatores, tratando cada um de forma independente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from nltk.corpus import floresta\n",
    "from textblob.classifiers import NaiveBayesClassifier, DecisionTreeClassifier\n",
    "from string import digits, punctuation\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "import numpy\n",
    "import stop_words\n",
    "import textblob\n",
    "import re\n",
    "import nltk\n",
    "import requests\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook vamos tentar aplicar o classificador Naive Bayes para classificar discursos dos parlamentares da Câmara dos Deputados proferidos em plenário. Os dados utilizados para análise foram obtidos através do [Babel](https://dev.babel.labhackercd.leg.br/), um repositórios de dados de manifestações políticas, e podem ser acessados pelo *endpoint*: https://dev.babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 discursos coletados\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://dev.babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=2')\n",
    "data = response.json()['results']\n",
    "response = requests.get('https://dev.babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=2&page=10')\n",
    "data += response.json()['results']\n",
    "response = requests.get('https://dev.babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=2&page=20')\n",
    "data += response.json()['results']\n",
    "\n",
    "speeches = []\n",
    "for speech in data:\n",
    "    for attr in speech['attrs']:\n",
    "        if attr['field'] == 'original':\n",
    "            speeches.append(attr['value'])\n",
    "            break\n",
    "\n",
    "print(len(speeches), 'discursos coletados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para limpar texto do discurso tirando as notas do taquigrafo\n",
    "def clear_speech(text):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[OA] SRA?[\\w\\s.]+-', '', text)\n",
    "    text = re.sub(r'PRONUNCIAMENTO[\\sA-Z]+\\s', '', text)\n",
    "#     text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s[\\.\\\"]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[Vv]\\.[Ee][Xx][Aa]\\.', 'v.exa', text)\n",
    "    text = re.sub(r'[Aa][Rr][Tt]\\.', 'art', text)\n",
    "    text = re.sub(r'[Ss][Rr][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'[Ss][Rr][Aa][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_text = clear_speech('. '.join(speeches))\n",
    "blob = textblob.TextBlob(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentenças\n",
    "\n",
    "Para realizar a classificação de um discurso, ele será divido em sentenças, utilizando a biblioteca TextBlob, e cada sentença será classificada individualmente e o conjunto de sentenças classificadas (uma sentença não precisa ser, necessariamente, classificada) definirá a classificação de um discurso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para se ter ideia, na Bahia, o PSDB está com uma propaganda no seu horário na televisão na qual os Deputados do PSDB dizem que o Governo da Bahia, na área da saúde, só faz propaganda.\n",
      "\n",
      "Esperamos, com relação a esse ponto, que a Comissão da Verdade revele os responsáveis, nestas empresas, pela cooperação com a tortura, o assassinato e outros crimes bárbaros cometidos pelo regime de exceção.\n",
      "\n",
      "A poucos dias da Copa do Mundo, o Brasil se prepara para dar início à Copa das Copas, uma competição cercada, é verdade, por graves denúncias , que estão sendo investigadas pela Justiça e por outros órgãos responsáveis, mas que colocará o Brasil no centro das atenções mundiais por quase quarenta dias.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(blob.sentences[23], end='\\n\\n')\n",
    "print(blob.sentences[233], end='\\n\\n')\n",
    "print(blob.sentences[100], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "*Stopwords* (ou palavras de parada – tradução livre) são palavras que podem ser consideradas irrelevantes para o conjunto de resultados a ser exibido em uma busca realizada em uma search engine. Exemplos: as, e, os, de, para, com, sem, foi. Esse conjunto de palavras pode variar em função do contexto em que será utilizado.\n",
    "\n",
    "Para esse notebook serão utilizadas as palavras fornecidas pela biblioteca NLTK, além de outras palavras selecionadas de acordo com os textos utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stop_words.get_stop_words('portuguese') + [\n",
    "    'presidente', ',', '.', '...', 'é', 'questão', 'art', 'ordem', 'v.exa', ':', 'governo', 'sr', 'agência', 'º',\n",
    "    'aqui', 'vai', 'artigo', '§', 'neste', 'vamos', 'agora', \"''\", 'fazer', 'mesa', 'ainda', 'porque', 'trata',\n",
    "    'estrutura', 'sobre', 'então', 'todos', 'obstrução', 'votação', 'presença', 'deputados', 'vou', 'brasil',\n",
    "    'discutir', 'vigência', 'colocar', 'regimento', 'momento', ';', 'dois', 'dessa', 'medida', 'proposta',\n",
    "    'casa', 'matéria', 'queria', 'assim', 'possamos', 'microfone', 'certeza', 'hoje', 'profissional', 'deixar',\n",
    "    'provisória', 'ora', 'base', 'importante', 'veto', 'fala', '!', 'ministério', 'aumento', 'inciso',\n",
    "    'manifestação', 'xiii', 'diálogo', 'podemos', 'apenas', 'poder', 'efeitos', 'pode', 'acordo', 'solicitação',\n",
    "    'reflexão', '?', 'ausência', 'aprovada', 'lideranças', 'dizer', 'bancada', 'portanto', 'peço', 'recolher',\n",
    "    'prática', 'pois', 'democracia', 'milhões', 'bilhões', 'melhoria', 'atividade', 'claro', 'saber', 'dar',\n",
    "    'avanço', 'condições', 'desastre', 'especialmente', 'exatamente', 'política', 'vezes', 'fazê-lo', 'têm',\n",
    "    'derrubar', 'precisa', 'custo', 'necessária', 'cláusula', 'proposição', '-', 'palavra', 'tempo', 'segundos',\n",
    "    'fez', 'necessário', 'zero', 'interesse', 'srs', 'sr', 'sras', 'sra', 'deputado', 'presidente', 'é', 'nº',\n",
    "    's.a.', 'v.exa.', 'v.exa', '#', 'anos', 'º', 'exa', 'mesa', 'legislatura', 'sessão', 'maioria', 'seguinte',\n",
    "    'mandato', 'bilhões', 'quilômetros', 'ª', 'parabéns', 'membros', 'convido', 'usual', 'biênio',\n",
    "    'brasil', 'palavra', 'discussão', 'período', 'início', 'pronunciamento', 'suplente', 'atividade', 'ação',\n",
    "    'ações', 'daqueles', 'diferenças', 'pasta', 'milhares', 'srªs', 'emenda', 'àqueles', 'tamanha', 'mês',\n",
    "    'capaz', 'km', 'modelo', 'tarefas', 'colegas', 'programa', 'voz', 'meios de comunicação', 'pronunciamento',\n",
    "    'casa', 'sessão', 'deliberativa', 'solene', 'ordinária', 'extraordinária', 'encaminhado', 'orador', 'tv',\n",
    "    'divulgar', 'deputado', 'parlamento', 'parlamentar', 'projeto', 'proposta', 'requerimento', 'destaque',\n",
    "    'veto', 'federal', 'câmara', 'senado', 'congresso', 'nacional', 'país', 'estado', 'brasil', 'lei',\n",
    "    'política', 'povo', 'voto', 'partido', 'liderança', 'bancada', 'bloco', 'líder', 'lider', 'frente',\n",
    "    'governo', 'oposição', 'presença', 'presente', 'passado', 'ausência', 'ausencia', 'ausente', 'obstrução',\n",
    "    'registrar', 'aprovar', 'rejeitar', 'rejeição', 'sabe', 'matéria', 'materia', 'questão', 'ordem', 'emenda',\n",
    "    'sistema', 'processo', 'legislativo', 'plenário', 'pedir', 'peço', 'comissão', 'especial', 'permanente',\n",
    "    'apresentar', 'encaminhar', 'encaminho', 'orientar', 'liberar', 'apoiar', 'situação', 'fato', 'revisão',\n",
    "    'tempo', 'pauta', 'discutir', 'discussão', 'debater', 'retirar', 'atender', 'colegas', 'autor', 'texto',\n",
    "    'medida', 'união', 'república', 'audiência', 'audiencia', 'público', 'publico', 'reunião', 'agradecer',\n",
    "    'solicitar', 'assistir', 'contrário', 'favorável', 'pessoa', 'comemorar', 'ato', 'momento', 'diretora',\n",
    "    'possível', 'atenção', 'agradeço', 'naquele', 'necessárias', 'presidenta', 'compromisso', 'geradas',\n",
    "    'primeiro', 'simplesmente', 'ideal', 'argumento', 'i', 'válido', 'envolvidos', 'nesse', 'aspecto',\n",
    "    'existentes', 'normativo', 'irá', 'nada', 'melhor', 'esperarmos', 'pouco', 'resolvermos', 'problema',\n",
    "    'postura', 'faltas', 'declara', '%', 'grande', 'dia', 'obrigado', 'agradeço', 'agradecido', 'população',\n",
    "    'maior', 'cada', 'bem', 'mundo', 'desta', 'mil', 'sendo', 'outros', '$', '!', '@', '#', '&', '(', ')', 'sim',\n",
    "    'r', 'sempre', 'além', 'semana', 'relação', 'onde', 'meio', 'inclusive', 'lá', 'vem', 'menos', 'menor',\n",
    "    'qualquer', 'desde', 'ontem', 'hoje', 'exemplos', 'exemplo', 'tão', 'fim', 'janeiro', 'fevereiro', 'março',\n",
    "    'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro', 'alguns', 'tudo',\n",
    "    'durante', 'gostaria', 'três', 'conta', 'feito', 'através', 'antes', 'depois', 'verdade', 'bom', 'quase',\n",
    "    'setor', 'aí', 'disse', 'principalmente', 'final', 'vão', 'coisa', 'ver', 'sentido', 'nova', 'vários', 'novo',\n",
    "    'nenhuma', 'quanto', 'infelizmente', 'felizmente', 'número', 'duas', 'dois', 'tanto', 'acho', 'achar',\n",
    "    'enquanto', 'deve', 'apelo', 'papel', 'últimos', 'faço', 'fazer', 'garantir', 'garantia', 'fica', 'obrigado',\n",
    "    'obrigado..', 'assunto', 'sido', 'vir', 'incrementar', 'central', 'aproximado', 'aproximadamente',\n",
    "    'hipotética', 'hipotese', 'hipótese', 'média', 'superior', 'superiores', 'gerais', 'venha', 'minas'\n",
    "]\n",
    "stopwords += [x for x in punctuation]\n",
    "stem_stopwords = [stemmer.stem(word) for word in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def simplify_tag(tag):\n",
    "    if \"+\" in tag:\n",
    "        return tag[tag.index(\"+\") + 1:]\n",
    "    else:\n",
    "        return tag\n",
    "\n",
    "floresta_twords = floresta.tagged_words()\n",
    "for (word, tag) in floresta_twords:\n",
    "    tag = simplify_tag(tag)\n",
    "    words = word.casefold().split('_')\n",
    "    if tag not in ('adj', 'n', 'prop', 'nprop', 'est', 'npro'):\n",
    "        stopwords += [stemmer.stem(word) for word in words]\n",
    "\n",
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras mais comuns\n",
      "[('trabalho', 206), ('saúde', 175), ('rio', 164), ('cidade', 139), ('vida', 135), ('sociedade', 132), ('ministro', 130), ('dilma', 123), ('trabalhadores', 120), ('polícia', 110), ('paulo', 105), ('segurança', 103), ('recursos', 102), ('educação', 102), ('justiça', 100), ('mulheres', 96), ('michel', 93), ('reais', 90), ('direito', 89), ('respeito', 87), ('presidente..', 86), ('crise', 85), ('social', 85), ('empresas', 84), ('tribuna', 82), ('prefeito', 82), ('pt', 81), ('dinheiro', 80), ('economia', 79), ('municípios', 79), ('município', 78), ('violência', 78), ('reforma', 77), ('servidores', 77), ('sul', 73), ('constituição', 73), ('crime', 73), ('urgência', 72), ('direitos', 71), ('área', 70), ('desenvolvimento', 68), ('pec', 68), ('maneira', 67), ('defesa', 67), ('corrupção', 67), ('nome', 64), ('oportunidade', 63), ('luta', 62), ('tribunal', 61), ('petrobras', 61), ('posição', 60), ('história', 60), ('bahia', 56), ('serviço', 56), ('dentro', 55), ('lula', 54), ('dá', 54), ('mulher', 53), ('lugar', 53), ('denúncia', 53), ('sociais', 52), ('cultura', 52), ('econômica', 51), ('eduardo', 51), ('mercado', 51), ('policiais', 51), ('parabenizar', 50), ('lado', 50), ('relator', 50), ('relatório', 50), ('responsabilidade', 49), ('hora', 49), ('dúvida', 49), ('fundo', 49), ('pagar', 49), ('ninguém', 48), ('militar', 48), ('discurso', 48), ('deus', 48), ('energia', 48), ('civil', 47), ('crimes', 47), ('participação', 47), ('decisão', 47), ('empresa', 47), ('trabalhador', 46), ('realmente', 46), ('agentes', 46), ('médicos', 46), ('nordeste', 45), ('iniciativa', 45), ('caminho', 45), ('conselho', 44), ('trabalhar', 44), ('pmdb', 44), ('fies', 44), ('carlos', 43), ('decreto', 43), ('jovens', 42), ('próprio', 42)]\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.tokenize.word_tokenize(cleaned_text)\n",
    "words = [word.casefold() for word in all_words if stemmer.stem(word) not in stem_stopwords]\n",
    "dist = nltk.FreqDist(words)\n",
    "print('Palavras mais comuns')\n",
    "print(dist.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse notebook, usaremos a implementação do TextBlob para classificar as sentenças. No TextBlob, podemos definir um método de extração de atributos (*feature extraction*) que são utilizados para comparar dois textos. Esse método deve receber como parâmetro o texto, pode receber um segundo argumento que contem os dados de treinamento e deve retornar um dicionário de atributos do texto recebido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'real': True,\n",
       " 'calcul': True,\n",
       " 'tax': True,\n",
       " 'patrimôni': True,\n",
       " 'rend': True,\n",
       " 'aplic': True,\n",
       " 'alíquot': True,\n",
       " 'simul': True,\n",
       " 'val': True}"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def freq_feature_extractor(document):\n",
    "    document = regex.sub(' ', document.casefold())\n",
    "    tokens = nltk.tokenize.word_tokenize(document)\n",
    "    tokens = [stemmer.stem(token) for token in tokens if stemmer.stem(token) not in stem_stopwords]\n",
    "    dist = nltk.FreqDist(tokens)\n",
    "    \n",
    "    features = {\n",
    "        stem: True\n",
    "#         stem: dist.freq(stem)\n",
    "        for stem, _ in dist.most_common()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "freq_feature_extractor('Calcula-se que a taxação de grandes patrimônios poderia render aproximadamente  bilhões de reais por ano se aplicada uma alíquota média de % sobre os bens das pessoas, em uma simulação hipotética, sobre valores superiores a  milhão de reais.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de treinamento\n",
    "\n",
    "A planilha de treinamento está disponível no [Google Drive](https://docs.google.com/spreadsheets/d/1qmJjRexlSUYOAN12IY_82NyOUaLZlbBsoeYRuulEjFE/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_RELATION = {\n",
    "    0: 'none',\n",
    "    1: 'adm-publica',\n",
    "    2: 'agricultura-pecuaria-pesca-extrativismo',\n",
    "    3: 'arte-cultura-religiao',\n",
    "    4: 'cidades-desenvolvimento-urbano',\n",
    "    5: 'ciencia-tecnologia-inovacao',\n",
    "    6: 'ciencias-exatas',\n",
    "    7: 'ciencias-sociais',\n",
    "    8: 'comunicacoes',\n",
    "    9: 'defesa-seguranca',\n",
    "    10: 'direito-civil',\n",
    "    11: 'direito-constitucional',\n",
    "    12: 'direito-consumidor',\n",
    "    13: 'direito-justica',\n",
    "    14: 'direito-penal',\n",
    "    15: 'direitos-humanos-minorias',\n",
    "    16: 'economia',\n",
    "    17: 'educacao',\n",
    "    18: 'energia-recursos-hidricos-minerais',\n",
    "    19: 'esporte-lazer',\n",
    "    20: 'estrutura-fundiaria',\n",
    "    21: 'financas-publicas-orcamento',\n",
    "    22: 'homenagens-datas-comemorativas',\n",
    "    23: 'industria-comercio-servicos',\n",
    "    24: 'meio-ambiente-desenvolvimento-sustentavel',\n",
    "    25: 'politica-partidos-eleicoes',\n",
    "    26: 'previdencia-assistencia-social',\n",
    "    27: 'processo-legislativo-atuacao-parlamentar',\n",
    "    28: 'relacoes-internacionais-comercio-exterior',\n",
    "    29: 'saude',\n",
    "    30: 'trabalho-emprego',\n",
    "    31: 'turismo',\n",
    "    32: 'viacao-transporte-mobilidade',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento de conteúdo: 708 sentenças\n",
      "Teste de conteúdo: 304 sentenças\n",
      "Treinamento de temas: 510 sentenças\n",
      "Teste de temas: 219 sentenças\n"
     ]
    }
   ],
   "source": [
    "theme_data = []\n",
    "content_data = []\n",
    "\n",
    "with open('naive-bayes-train.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        for idx, category in enumerate(row[1:-1]):\n",
    "            if category != '' and idx > 0:\n",
    "                theme_data.append((row[0], LABELS_RELATION[idx]))\n",
    "                content_data.append((row[0], 'content'))\n",
    "            elif category != '' and idx == 0:\n",
    "                content_data.append((row[0], 'useless'))\n",
    "\n",
    "shuffle(content_data)\n",
    "content_data_size = len(content_data)\n",
    "content_train = content_data[:math.floor(content_data_size * 0.7)]\n",
    "content_test = content_data[math.floor(content_data_size * 0.7):]\n",
    "print('Treinamento de conteúdo: {} sentenças'.format(len(content_train)))\n",
    "print('Teste de conteúdo: {} sentenças'.format(len(content_test)))\n",
    "\n",
    "shuffle(theme_data)\n",
    "theme_data_size = len(theme_data)\n",
    "theme_train = theme_data[:math.floor(theme_data_size * 0.7)]\n",
    "theme_test = theme_data[math.floor(theme_data_size * 0.7):]\n",
    "print('Treinamento de temas: {} sentenças'.format(len(theme_train)))\n",
    "print('Teste de temas: {} sentenças'.format(len(theme_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_classifier = NaiveBayesClassifier(content_train, feature_extractor=freq_feature_extractor)\n",
    "content_classifier.accuracy(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0319634703196347"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_classifier = NaiveBayesClassifier(theme_train, feature_extractor=freq_feature_extractor)\n",
    "theme_classifier.accuracy(theme_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2557077625570776"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_classifier = DecisionTreeClassifier(theme_train, feature_extractor=freq_feature_extractor)\n",
    "theme_classifier.accuracy(theme_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos macro-temas\n",
    "\n",
    "Para melhorar a acurácia do classificador, os 32 temas serão agrupados em macrotemas, para facilitar a classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACRO_THEMES_RELATION = {\n",
    "    'cidades-desenvolvimento-urbano': 'cidades-transportes',\n",
    "    'viacao-transporte-mobilidade': 'cidades-transportes',\n",
    "    \n",
    "    'comunicacoes': 'ct-comunicacoes',\n",
    "    'ciencia-tecnologia-inovacao': 'ct-comunicacoes',\n",
    "    'ciencias-exatas': 'ct-comunicacoes',\n",
    "    \n",
    "    'defesa-seguranca': 'seguranca',\n",
    "    \n",
    "    'previdencia-assistencia-social': 'trabalho-previdencia-assistencia',\n",
    "    'trabalho-emprego': 'trabalho-previdencia-assistencia',\n",
    "    \n",
    "    'relacoes-internacionais-comercio-exterior': 'relacoes-exteriores',\n",
    "    \n",
    "    'saude': 'saude',\n",
    "    \n",
    "    'arte-cultura-religiao': 'educacao-cultura-esporte',\n",
    "    'educacao': 'educacao-cultura-esporte',\n",
    "    'esporte-lazer': 'educacao-cultura-esporte',\n",
    "    'turismo': 'educacao-cultura-esporte',\n",
    "    \n",
    "    'homenagens-datas-comemorativas': 'politica-adm-publica',\n",
    "    'politica-partidos-eleicoes': 'politica-adm-publica',\n",
    "    'processo-legislativo-atuacao-parlamentar': 'politica-adm-publica',\n",
    "    'adm-publica': 'politica-adm-publica',\n",
    "    \n",
    "    'ciencias-sociais': 'direitos-humanos',\n",
    "    'direitos-humanos-minorias': 'direitos-humanos',\n",
    "    \n",
    "    'agricultura-pecuaria-pesca-extrativismo': 'agropecuaria',\n",
    "    'estrutura-fundiaria': 'agropecuaria',\n",
    "    \n",
    "    'financas-publicas-orcamento': 'economia',\n",
    "    'economia': 'economia',\n",
    "    \n",
    "    'meio-ambiente-desenvolvimento-sustentavel': 'meio-ambiente-energia',\n",
    "    'energia-recursos-hidricos-minerais': 'meio-ambiente-energia',\n",
    "    \n",
    "    'direito-consumidor': 'consumidor',\n",
    "    'industria-comercio-servicos': 'consumidor',\n",
    "    \n",
    "    'direito-civil': 'justica',\n",
    "    'direito-constitucional': 'justica',\n",
    "    'direito-justica': 'justica',\n",
    "    'direito-penal': 'justica',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento de macro temas: 510 sentenças\n",
      "Teste de macro temas: 219 sentenças\n"
     ]
    }
   ],
   "source": [
    "macrotheme_data = [(sentence, MACRO_THEMES_RELATION[label]) for sentence, label in theme_data]\n",
    "shuffle(macrotheme_data)\n",
    "macrotheme_data_size = len(macrotheme_data)\n",
    "macrotheme_train = macrotheme_data[:math.floor(macrotheme_data_size * 0.7)]\n",
    "macrotheme_test = macrotheme_data[math.floor(macrotheme_data_size * 0.7):]\n",
    "print('Treinamento de macro temas: {} sentenças'.format(len(macrotheme_train)))\n",
    "print('Teste de macro temas: {} sentenças'.format(len(macrotheme_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.365296803652968"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macrotheme_classifier = DecisionTreeClassifier(macrotheme_train, feature_extractor=freq_feature_extractor)\n",
    "macrotheme_classifier.accuracy(macrotheme_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  Categorias:\n",
      "['ct-comunicacoes', 'consumidor', 'agropecuaria', 'direitos-humanos', 'trabalho-previdencia-assistencia', 'seguranca', 'politica-adm-publica', 'meio-ambiente-energia', 'cidades-transportes', 'educacao-cultura-esporte', 'justica', 'saude', 'economia']\n"
     ]
    }
   ],
   "source": [
    "print(len(macrotheme_classifier.labels()), ' Categorias:')\n",
    "print(macrotheme_classifier.labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACRO_THEMES_TRAIN = {\n",
    "    'ct-comunicacoes': [],\n",
    "    'consumidor': [],\n",
    "    'agropecuaria': [],\n",
    "    'direitos-humanos': [],\n",
    "    'saude': [],\n",
    "    'seguranca': [],\n",
    "    'politica-adm-publica': [],\n",
    "    'meio-ambiente-energia': [], \n",
    "    'cidades-transportes': [],\n",
    "    'educacao-cultura-esporte': [],\n",
    "    'justica': [],\n",
    "    'trabalho-previdencia-assistencia': [],\n",
    "    'economia': [],\n",
    "    'relacoes-exteriores': [],\n",
    "}\n",
    "\n",
    "for sentence, label in theme_data:\n",
    "    macro_theme = MACRO_THEMES_RELATION[label]\n",
    "    train_list = MACROTHEMES_TRAIN.get(macro_theme, [])\n",
    "    train_list.append((sentence, label)) \n",
    "    MACRO_THEMES_TRAIN[macro_theme] = train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ct-comunicacoes classifier with 35 sentences\n",
      "Training finished! Testing with 16 . Accuracy:  1.0\n",
      "\n",
      "Training consumidor classifier with 31 sentences\n",
      "Training finished! Testing with 14 . Accuracy:  1.0\n",
      "\n",
      "Training agropecuaria classifier with 98 sentences\n",
      "Training finished! Testing with 43 . Accuracy:  0.9767441860465116\n",
      "\n",
      "Training direitos-humanos classifier with 134 sentences\n",
      "Training finished! Testing with 58 . Accuracy:  0.8620689655172413\n",
      "\n",
      "Training saude classifier with 54 sentences\n",
      "Training finished! Testing with 24 . Accuracy:  1.0\n",
      "\n",
      "Training seguranca classifier with 90 sentences\n",
      "Training finished! Testing with 39 . Accuracy:  1.0\n",
      "\n",
      "Training politica-adm-publica classifier with 503 sentences\n",
      "Training finished! Testing with 217 . Accuracy:  0.9032258064516129\n",
      "\n",
      "Training meio-ambiente-energia classifier with 96 sentences\n",
      "Training finished! Testing with 42 . Accuracy:  0.7857142857142857\n",
      "\n",
      "Training cidades-transportes classifier with 52 sentences\n",
      "Training finished! Testing with 23 . Accuracy:  1.0\n",
      "\n",
      "Training educacao-cultura-esporte classifier with 136 sentences\n",
      "Training finished! Testing with 59 . Accuracy:  0.9152542372881356\n",
      "\n",
      "Training justica classifier with 60 sentences\n",
      "Training finished! Testing with 27 . Accuracy:  0.8148148148148148\n",
      "\n",
      "Training economia classifier with 165 sentences\n",
      "Training finished! Testing with 72 . Accuracy:  0.9861111111111112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MACRO_THEMES_CLASSIFIERS = {\n",
    "    'ct-comunicacoes': None,\n",
    "    'consumidor': None,\n",
    "    'agropecuaria': None,\n",
    "    'direitos-humanos': None,\n",
    "    'saude': None,\n",
    "    'seguranca': None,\n",
    "    'politica-adm-publica': None,\n",
    "    'meio-ambiente-energia': None, \n",
    "    'cidades-transportes': None,\n",
    "    'educacao-cultura-esporte': None,\n",
    "    'justica': None,\n",
    "    'trabalho-previdencia-assistencia': None,\n",
    "    'economia': None,\n",
    "    'relacoes-exteriores': None,\n",
    "}\n",
    "\n",
    "for macrotheme in MACRO_THEME_CLASSIFIERS.keys():\n",
    "    macrotheme_data = MACRO_THEMES_TRAIN[macrotheme]\n",
    "\n",
    "    shuffle(macrotheme_data)\n",
    "    macrotheme_data_size = len(macrotheme_data)\n",
    "    macrotheme_train = macrotheme_data[:math.floor(macrotheme_data_size * 0.7)]\n",
    "    macrotheme_test = macrotheme_data[math.floor(macrotheme_data_size * 0.7):]\n",
    "\n",
    "    if len(macrotheme_train):\n",
    "        print('Training', macrotheme, 'classifier with', len(macrotheme_train), 'sentences')\n",
    "        macrotheme_classifier = NaiveBayesClassifier(macrotheme_train)\n",
    "        MACRO_THEMES_CLASSIFIERS[macrotheme] = macrotheme_classifier\n",
    "        print('Training finished! Testing with', len(macrotheme_test), '. Accuracy: ', macrotheme_classifier.accuracy(macrotheme_test), end='\\n\\n')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
