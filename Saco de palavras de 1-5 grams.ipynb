{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saco de palavras de 1-5 grams \n",
    "\n",
    "## Solução:\n",
    "1. Criar uma lista de \"stopwords\" adequada para termos de \"n\" palavras;\n",
    "2. Gerar uma lista de \"tokens\" removendo pontuação e as \"stopwords\";\n",
    "3. Criar 5 grupos de ngrams, de 1 a 5 palavras;\n",
    "4. Definir um limite de ocorrências mínimo;\n",
    "5. Iterar entre os grupos, removendo os termos duplicados de ngrams menores, por exemplo:\n",
    "    * Se houver um bigram (('sindicato', 'metalúrgico'), 5), os onegram (('sindicato',), 5) e (('metalúrgico',), 5) são removidos.\n",
    "6. São somados os 5 grupos e retorna a lista de termos mais frequentes.\n",
    "\n",
    "## Conclusão:\n",
    "1. Quanto maior a base de discursos processados, melhor o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Endereço da API dos discursos\n",
    "BABEL_API_URL = 'https://babel.labhackercd.leg.br/api/v1/manifestations?manifestation_type__id=1'\n",
    "\n",
    "# Pegando os 200 primeiros discursos da API do Babel\n",
    "speeches = []\n",
    "data = requests.get(BABEL_API_URL).json()['results']\n",
    "for i in range(2, 50):\n",
    "    data += requests.get(BABEL_API_URL + '&page=%s' % i).json()['results']\n",
    "    \n",
    "for speech in data:\n",
    "    for attr in speech['attrs']:\n",
    "        if attr['field'] == 'original':\n",
    "            speeches.append(attr['value'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limite mínimo de ocorrências: 75\n"
     ]
    }
   ],
   "source": [
    "# Criando a lista de stopwords em português\n",
    "EXTRA_STOPWORDS = [\n",
    "    'sr.', 'nesse', 'deputados', '``', \"''\", 'empresa', 'trabalhadores', 'tema', 'brasil', 'brasileiro',\n",
    "    'brasileira', 'sociedade', 'grandes', 'meios', 'principal', 'deputada', 'nesta', 'valor', 'reais',\n",
    "    'representante', 'brasileiros', 'necessidade', 'quero', 'ser', 'geral', 'todo', 'toda', 'estar',\n",
    "    'ter', 'parlamentares', 'região', 'forma', 'parte', 'disso', 'debate', 'entregar', 'nessa', 'nome',\n",
    "    'vez', 'quer', 'primeira', 'soberania', 'justamente', 'ponto', 'presentes', 'faz', 'futuro', 'podem',\n",
    "    'maneira', 'falar', 'interesses', 'caso', 'espaço', 'entrega', 'deste', 'mesma', 'negócio', 'existe',\n",
    "    'avançar', 'ano', 'diz', 'próprios', 'criação', 'própria', 'dizendo', 'trazer', 'preocupação', 'ali',\n",
    "    'ficar', 'desse', 'importância', 'senhor', 'queremos', 'poderia', 'ir', 'próprio', 'área', 'segundo',\n",
    "    'acontece', 'sei', 'sabem', 'comum', 'mim', 'tratar', 'obrigação', 'falando', 'discurso', 'muitas',\n",
    "    'acabou', 'falou', 'outro', 'capacidade', 'força','querem', 'significa', 'serviço', 'dados', 'tentar',\n",
    "    'ninguém', 'gente', 'ideia', 'deputadas', 'dentro', 'fazendo', 'mão', 'época', 'uso', 'fiz', 'último',\n",
    "    'nenhum', 'números', 'alguma', 'acreditamos', 'achamos', 'pagar', 'paga', 'conjunto', 'contentam',\n",
    "    'lacunas', 'esperamos', 'digo', 'sente', 'logo', 'pesquisar', 'principais', 'mudar', 'sequer', 'pagou',\n",
    "    'pagando', 'traz', 'desafio', 'concreto', 'atende', 'tendo', 'aberto', 'curto', 'recebe', 'receber',\n",
    "    'décadas', 'minutos', 'horas', 'segundos', 'motivo', 'posso', 'dando', 'entra', 'volto', 'construir',\n",
    "    'algumas', 'passar', 'muita', 'nisso', 'deveria', 'dá', 'construir', 'muito', 'longo', 'muitas', 'outras',\n",
    "    'existem', 'conseguimos', 'precisamos', 'feita', 'mencionou', 'falei', 'cujo', 'hora', 'dizia', 'venha',\n",
    "    'conseguindo', 'conseguir', 'votar', 'alguém', 'somente', 'todas', 'fizemos', 'citar', 'saiba', 'boa',\n",
    "    'deveriam', 'acontecendo', 'algo', 'apresentei', 'sabemos', 'outra', 'junto', 'daqui', 'aconteceu',\n",
    "    'haver', 'sinto', 'preciso', 'muitos', 'minimamente', 'amanhã', 'ontem', 'partir', 'objetivo', 'opinião',\n",
    "    'vivemos', 'discutindo', 'agradecemos', 'utilizados', 'contra', 'dona', 'falta', 'possa', 'manhã', 'novas',\n",
    "    'após', 'pessoas', 'fundamental', 'desses', 'devido', 'item', 'século', 'domingo', 'sábado',\n",
    "    'presidente', ',', '.', '...', 'é', 'questão', 'art', 'ordem', 'v.exa', ':', 'governo', 'sr', 'agência',\n",
    "    'aqui', 'vai', 'artigo', '§', 'neste', 'vamos', 'agora', \"''\", 'fazer', 'mesa', 'ainda', 'porque', 'trata',\n",
    "    'estrutura', 'sobre', 'então', 'todos', 'obstrução', 'votação', 'presença', 'deputados', 'vou', 'brasil',\n",
    "    'discutir', 'vigência', 'colocar', 'regimento', 'momento', ';', 'dois', 'dessa', 'medida', 'proposta',\n",
    "    'casa', 'matéria', 'queria', 'assim', 'possamos', 'microfone', 'certeza', 'hoje', 'profissional', 'deixar',\n",
    "    'provisória', 'ora', 'base', 'importante', 'veto', 'fala', '!', 'aumento', 'inciso', 'sra.', 'talvez',\n",
    "    'cima', 'servir', 'nunca', 'dias', 'deus', 'dei', 'entendemos', 'chega', 'possam', 'entendo', 'poderá',\n",
    "    'celeridade', 'tirar', 'mista', 'fechou-se', 'lado', 'lido', 'repassado', 'demais', 'venho', 'marcar',\n",
    "    'xiii', 'diálogo', 'podemos', 'apenas', 'poder', 'efeitos', 'pode', 'acordo', 'solicitação',\n",
    "    'reflexão', '?', 'ausência', 'aprovada', 'lideranças', 'dizer', 'portanto', 'peço', 'recolher',\n",
    "    'prática', 'pois', 'milhões', 'bilhões', 'melhoria', 'atividade', 'claro', 'saber', 'dar',\n",
    "    'avanço', 'condições', 'desastre', 'especialmente', 'exatamente', 'política', 'vezes', 'fazê-lo', 'têm',\n",
    "    'derrubar', 'precisa', 'custo', 'necessária', 'cláusula', 'proposição', '-', 'palavra', 'tempo', 'segundos',\n",
    "    'fez', 'necessário', 'zero', 'interesse', 'srs', 'sr', 'sras', 'sra', 'deputado', 'presidente', 'é', 'nº',\n",
    "    's.a.', 'v.exa.', 'v.exa', '#', 'anos', 'º', 'exa', 'mesa', 'legislatura', 'sessão', 'maioria', 'seguinte',\n",
    "    'mandato', 'bilhões', 'quilômetros', 'ª', 'parabéns', 'membros', 'convido', 'usual', 'biênio',\n",
    "    'brasil', 'palavra', 'discussão', 'período', 'início', 'pronunciamento', 'suplente', 'atividade', 'ação',\n",
    "    'ações', 'daqueles', 'diferenças', 'pasta', 'milhares', 'srªs', 'emenda', 'àqueles', 'tamanha', 'mês',\n",
    "    'capaz', 'km', 'modelo', 'tarefas', 'colegas', 'programa', 'voz', 'pronunciamento',\n",
    "    'casa', 'sessão', 'deliberativa', 'solene', 'ordinária', 'extraordinária', 'encaminhado', 'orador',\n",
    "    'divulgar', 'deputado', 'parlamentar', 'projeto', 'proposta', 'requerimento', 'destaque',\n",
    "    'veto', 'câmara', 'senado', 'congresso', 'país', 'estado', 'brasil', 'lei', 'novo', 'nova',\n",
    "    'política', 'povo', 'voto', 'partido', 'liderança', 'bancada', 'bloco', 'líder', 'lider', 'frente',\n",
    "    'governo', 'oposição', 'presença', 'presente', 'passado', 'ausência', 'ausencia', 'ausente', 'obstrução',\n",
    "    'registrar', 'aprovar', 'rejeitar', 'rejeição', 'sabe', 'matéria', 'materia', 'questão', 'ordem', 'emenda',\n",
    "    'sistema', 'processo', 'legislativo', 'plenário', 'pedir', 'peço', 'comissão', 'especial', 'permanente',\n",
    "    'apresentar', 'encaminhar', 'encaminho', 'orientar', 'liberar', 'apoiar', 'situação', 'fato', 'revisão',\n",
    "    'tempo', 'pauta', 'discutir', 'discussão', 'debater', 'retirar', 'atender', 'colegas', 'autor', 'texto',\n",
    "    'medida', 'união', 'república', 'audiência', 'audiencia', 'público', 'publico', 'reunião', 'agradecer',\n",
    "    'solicitar', 'assistir', 'contrário', 'favorável', 'pessoa', 'comemorar', 'ato', 'momento', 'diretora',\n",
    "    'possível', 'atenção', 'agradeço', 'naquele', 'necessárias', 'presidenta', 'compromisso', 'geradas',\n",
    "    'primeiro', 'simplesmente', 'ideal', 'argumento', 'i', 'válido', 'envolvidos', 'nesse', 'aspecto',\n",
    "    'existentes', 'normativo', 'irá', 'nada', 'melhor', 'esperarmos', 'pouco', 'resolvermos', 'problema',\n",
    "    'postura', 'faltas', 'declara', '%', 'dia', 'obrigado', 'agradeço', 'agradecido', 'população',\n",
    "    'maior', 'cada', 'bem', 'mundo', 'desta', 'mil', 'sendo', 'outros', '$', '!', '@', '#', '&', '(', ')',\n",
    "    'r', 'sempre', 'além', 'semana', 'relação', 'onde', 'meio', 'inclusive', 'lá', 'vem', 'menos', 'menor',\n",
    "    'qualquer', 'desde', 'ontem', 'hoje', 'exemplos', 'exemplo', 'tão', 'fim', 'janeiro', 'fevereiro', 'março',\n",
    "    'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro', 'alguns',\n",
    "    'durante', 'gostaria', 'três', 'conta', 'feito', 'através', 'antes', 'depois', 'verdade', 'bom', 'quase',\n",
    "    'setor', 'aí', 'disse', 'principalmente', 'final', 'vão', 'coisa', 'ver', 'sentido', 'vários',\n",
    "    'nenhuma', 'quanto', 'infelizmente', 'felizmente', 'número', 'duas', 'dois', 'tanto', 'acho', 'achar',\n",
    "    'enquanto', 'deve', 'apelo', 'papel', 'últimos', 'faço', 'fazer', 'garantir', 'garantia', 'fica',\n",
    "    'obrigado..', 'assunto', 'sido', 'vir', 'incrementar', 'central', 'aproximado', 'aproximadamente',\n",
    "    'hipotética', 'hipotese', 'hipótese', 'superiores', 'entende', 'pedido', 'oradora', 'tal', 'v.exas',\n",
    "    'favor', 'vota', 'nº', 'srª', 'vista', 'sim', 'dito', 'tudo', 'obrigado', 'º', 'profundamente', 'custódio',\n",
    "    'divulgado', 'características', 'perfeito', 'começarmos', 'nomes', 'amigo', 'possibilidade', 'mensagem',\n",
    "    'come', 'parabenizar', 'começar', 'hs', 'atendimento', 'povos', '¯', 'ocorreu', 'entanto', 'diante',\n",
    "    'defender', 'dr.', '“', '”', '•', 'v.', './', 'és', 'senhoras', 'senhores', 'tipo', 'várias', 'gerais',\n",
    "    'quais', 'dessas', 'deu', 'havia', 'devem', 'enfim', 'apesar', 'passa', 'chegou', 'vêm', 'parece', 'u'\n",
    "]\n",
    "\n",
    "ONEGRAM_STOPWORDS = [\n",
    "    'grande', 'nacional', 'são', 'e', 'de', 'das', 'dos', 'da', 'do', 'federal', 'cedo', 'urgência', 'equipe',\n",
    "    'produtos', 'serviços', 'pequeno', 'total', 'podermos', 'consenso', 'popular', 'mérito', 'único', 'pública',\n",
    "    'escolha', 'acesso', 'pilotos', 'trabalhar', 'ministério', 'países', 'combate', 'estados', 'vida', 'cidade',\n",
    "    'municípios', 'histórico', 'defesa', 'município', 'prefeito', 'ii', 'santa', 'vereadora', 'centro',\n",
    "    'prefeitura', 'governador', 'código', 'apoio', 'exercício', 'categoria', 'campo', 'kit',\n",
    "    'ministro', 'social', 'recursos', 'direito', 'empresas', 'comunicação', 'democracia',\n",
    "    'tribuna', 'história', 'respeito', 'luta', 'oportunidade', 'dinheiro', 'públicos',\n",
    "    'civil', 'qualidade', 'políticas', 'sociais', 'registro', 'públicas', 'crescimento',\n",
    "    'responsabilidade', 'participação', 'importantes', 'gestão', 'minas', 'cidades', 'lugar',\n",
    "    'problemas', 'decisão', 'mulher', 'nobre', 'capital', 'aprovação', 'humanos', 'estadual',\n",
    "    'internacional', 'senador', 'redução', 'realmente', 'realidade', 'plano', 'partidos',\n",
    "    'conselho', 'posição', 'medidas', 'termos', 'divulgação', 'econômico', 'federais', 'fiscal',\n",
    "    'emprego', 'maiores', 'rede', 'ruas', 'regional', 'continuar', 'profissionais', 'sob',\n",
    "    'homens', 'político', 'atual', 'nação', 'meses', 'grupo', 'áreas', 'fundo', 'iniciativa',\n",
    "    'executivo', 'cerca', 'cidadão', 'prazo', 'homem', 'trabalhador', 'órgãos', 'campanha',\n",
    "    'controle', 'mínimo', 'mundial', 'dúvida', 'legislação', 'relatório', 'emendas', 'atividades',\n",
    "    'razão', 'resultado', 'instituições', 'brasileiras', 'líderes', 'última', 'secretário', 'precisam',\n",
    "    'criar', 'movimento', 'data', 'fazem', 'novos', 'casos', 'ambiente', 'administração', 'distrito',\n",
    "    'pesquisa', 'relator', 'cumprimento', 'causa', 'informações', 'evento', 'aliás', 'superior',\n",
    "    'filho', 'tarde', 'caminho', 'dificuldades', 'risco', 'publicação', 'sobretudo', 'coisas',\n",
    "    'obrigada', 'santo', 'solicito', 'cargos', 'condição', 'próximo', 'secretaria', 'formação',\n",
    "    'penal', 'forte', 'representa', 'aprovado', 'acima', 'políticos', 'setores', 'chegar',\n",
    "    'espírito', 'prefeitos', 'grave', 'solução', 'governos', 'conhecimento', 'espero',\n",
    "    'preço', 'mudança', 'instituto', 'tributária', 'amigos', 'levar', 'diversos',\n",
    "    'municipal', 'dado', 'filhos', 'proteção', 'pagamento', 'federação', 'entidades',\n",
    "    'br-', 'funcionários', 'média', 'organização', 'veículos', 'difícil', 'patrimônio',\n",
    "    'marco', 'geração', 'diversas', 'honra', 'aumentar', 'movimentos', 'idade', 'passou',\n",
    "    'inclusão', 'responsável', 'única', 'busca', 'questões', 'operação', 'participar',\n",
    "    'pequenos', 'ajudar', 'regime', 'vítimas', 'pior', 'orgulho', 'unidos', 'embora',\n",
    "    'forças', 'inteiro', 'modo', 'simples', 'programas', 'legislativa', 'caixa', 'leis',\n",
    "    'passada', 'cidadãos', 'dignidade', 'associação', 'absolutamente', 'contribuição',\n",
    "    'trata-se', 'esforço', 'representantes', 'fizeram', 'vereador', 'ficou', 'volta',\n",
    "    'quadro', 'lembrar', 'concluir', 'votos', 'classe', 'atuação', 'médio', 'receita',\n",
    "    'palavras', 'nível', 'encontro', 'milhão', 'diferente', 'local', 'estaduais',\n",
    "    'constitucional', 'recurso', 'certamente', 'nossa'\n",
    "]\n",
    "\n",
    "\n",
    "# Método para limpar texto do discurso tirando as notas do taquigrafo\n",
    "def clear_speech(text):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[OA] SRA?[\\w\\s.]+-', '', text)\n",
    "    text = re.sub(r'PRONUNCIAMENTO[\\sA-Z]+\\s', '', text)\n",
    "#     text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s[\\.\\\"]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[Vv]\\.[Ee][Xx][Aa]\\.', 'v.exa', text)\n",
    "    text = re.sub(r'[Aa][Rr][Tt]\\.', 'art', text)\n",
    "    text = re.sub(r'[Ss][Rr][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'[Ss][Rr][Aa][Ss]?\\.', 'sr', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def get_tokens(speeches, extra_stopwords=None):\n",
    "    \"\"\"\n",
    "    Função que retorna tokens de discursos removendo as \"stopwords\".\n",
    "    Argumentos:\n",
    "        speeches: Recebe uma lista de discursos.\n",
    "        stopwords: Recebe uma lista de palavras a serem retiradas dos textos.\n",
    "    Retorna:\n",
    "        Uma lista palavras do discurso que não estão nas \"stopwords\".\n",
    "    \"\"\"\n",
    "    special_stopwords = ['são', 'nossa']\n",
    "    stopwords = nltk_stopwords.words('portuguese') + list(punctuation) + EXTRA_STOPWORDS\n",
    "    stopwords = [word for word in stopwords if word not in special_stopwords]\n",
    "    if extra_stopwords:\n",
    "        stopwords += extra_stopwords\n",
    "    tokens = []\n",
    "    for text in speeches:\n",
    "        text = clear_speech(text)\n",
    "        tokens += [i for i in word_tokenize(text.lower(), language='portuguese') if i not in stopwords]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def ngrams_by_limit(tokens, n, limit):\n",
    "    \"\"\"\n",
    "    Função que retorna uma lista de ngrams de acordo com os argumento passados.\n",
    "    Argumentos:\n",
    "        tokens: Recebe uma lista de tokens já processados pelo nltk.word_tokenize.\n",
    "        n: Recebe o número de palavras que deseja dividir o ngram.\n",
    "        limit: Recebe o limite mínimo de ocorrência.\n",
    "    Retorna:\n",
    "        Uma lista de ngrams com ocorrência maior que \"limite\" e com \"n\" palavras.\n",
    "    \"\"\"\n",
    "    ngrams_count = Counter(ngrams(tokens, n)).most_common()\n",
    "    result = [x for x in ngrams_count if x[1] >= limit]\n",
    "    return result\n",
    "\n",
    "\n",
    "def clean_tokens(tokens, fivegrams=[], quadgrams=[], trigrams=[], bigrams=[], extra_stopwords=None):\n",
    "    \"\"\"\n",
    "    Função que retorna uma lista de tokens filtradas pelos argumentos passados.\n",
    "    Argumentos:\n",
    "        tokens: Recebe uma lista de tokens já processados pelo nltk.word_tokenize.\n",
    "        fivegrams: Recebe uma lista de fivegrams.\n",
    "        quadgrams: Recebe uma lista de quadgrams.\n",
    "        trigrams: Recebe uma lista de trigramas.\n",
    "        bigrams: Recebe uma lista de bigramas.\n",
    "        extra_stopwords: Recebe uma lista de stopwords.\n",
    "    Retorna:\n",
    "        Uma lista de tokens removendo os n-gramas e stopwords passados nos argumentos.\n",
    "    \"\"\"\n",
    "    \n",
    "    if fivegrams:\n",
    "        pos_fivegram = []\n",
    "        for i in range(len(tokens)-4):\n",
    "            for word1, word2, word3, word4, word5 in fivegrams:\n",
    "                if (tokens[i] == word1 and tokens[i+1] == word2 and tokens[i+2] == word3 and\n",
    "                    tokens[i+3] == word4 and tokens[i+4] == word5):\n",
    "                    pos_fivegram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_fivegram):\n",
    "            del tokens[pos:pos+5]\n",
    "      \n",
    "    if quadgrams:\n",
    "        pos_quadgram = []\n",
    "        for i in range(len(tokens)-3):\n",
    "            for word1, word2, word3, word4 in quadgrams:\n",
    "                if (tokens[i] == word1 and tokens[i+1] == word2 and tokens[i+2] == word3 and\n",
    "                    tokens[i+3] == word4):\n",
    "                    pos_quadgram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_quadgram):\n",
    "            del tokens[pos:pos+4]\n",
    "\n",
    "    if trigrams:\n",
    "        pos_trigram = []\n",
    "        for i in range(len(tokens)-2):\n",
    "            for word1, word2, word3 in trigrams:\n",
    "                if tokens[i] == word1 and tokens[i+1] == word2 and tokens[i+2] == word3:\n",
    "                    pos_trigram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_trigram):\n",
    "            del tokens[pos:pos+3]\n",
    "\n",
    "    if bigrams:\n",
    "        pos_bigram = []\n",
    "        for i in range(len(tokens)-1):\n",
    "            for word1, word2 in bigrams:\n",
    "                if tokens[i] == word1 and tokens[i+1] == word2:\n",
    "                    pos_bigram.append(i)\n",
    "\n",
    "        for pos in reversed(pos_bigram):\n",
    "            del tokens[pos:pos+2]\n",
    "    \n",
    "    if extra_stopwords:\n",
    "        new_tokens = [token for token in tokens if token not in extra_stopwords]\n",
    "    else:\n",
    "        new_tokens = tokens\n",
    "\n",
    "    return new_tokens\n",
    "\n",
    "#Definimos os tokens\n",
    "tokens = get_tokens(speeches)\n",
    "\n",
    "# Determinamos o limite de ocorrências usado no algoritmo\n",
    "limit = Counter(tokens).most_common(int(len(speeches) * 0.2))[-1][1]\n",
    "if limit < 3:\n",
    "    limit = 3\n",
    "\n",
    "print(\"Limite mínimo de ocorrências: %s\" % limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo termos com 5 palavras\n",
    "fivegrams = ngrams_by_limit(tokens, 5, limit)\n",
    "fivegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo termos com 4 palavras\n",
    "stop_fivegrams = []\n",
    "\n",
    "if fivegrams:\n",
    "    stop_fivegrams = list(list(zip(*fivegrams))[0])\n",
    "\n",
    "quadgram_tokens = clean_tokens(tokens, stop_fivegrams)\n",
    "quadgrams = ngrams_by_limit(quadgram_tokens, 4, limit)\n",
    "quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('supremo', 'tribunal', 'federal'), 129), (('rio', 'grande', 'sul'), 84)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo termos com 3 palavras\n",
    "stop_fivegrams = stop_quadgrams = []\n",
    "\n",
    "if fivegrams:\n",
    "    stop_fivegrams = list(list(zip(*fivegrams))[0])\n",
    "\n",
    "if quadgrams:\n",
    "    stop_quadgrams = list(list(zip(*quadgrams))[0])\n",
    "\n",
    "trigram_tokens = clean_tokens(tokens, stop_fivegrams, stop_quadgrams)\n",
    "trigrams = ngrams_by_limit(trigram_tokens, 3, limit)\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('michel', 'temer'), 202),\n",
       " (('dilma', 'rousseff'), 194),\n",
       " (('eduardo', 'cunha'), 166),\n",
       " (('são', 'paulo'), 145),\n",
       " (('polícia', 'federal'), 108),\n",
       " (('distrito', 'federal'), 107),\n",
       " (('segurança', 'pública'), 91),\n",
       " (('crime', 'responsabilidade'), 84),\n",
       " (('ex-presidente', 'lula'), 82),\n",
       " (('operação', 'lava-jato'), 78)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo termos com 2 palavras\n",
    "stop_fivegrams = stop_quadgrams = stop_trigrams = []\n",
    "\n",
    "if fivegrams:\n",
    "    stop_fivegrams = list(list(zip(*fivegrams))[0])\n",
    "    \n",
    "if quadgrams:\n",
    "    stop_quadgrams = list(list(zip(*quadgrams))[0])\n",
    "\n",
    "if trigrams:\n",
    "    stop_trigrams = list(list(zip(*trigrams))[0])\n",
    "\n",
    "bigram_tokens = clean_tokens(tokens, stop_fivegrams, stop_quadgrams, stop_trigrams)\n",
    "bigrams = ngrams_by_limit(bigram_tokens, 2, limit)\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('impeachment',), 521),\n",
       " (('golpe',), 497),\n",
       " (('saúde',), 461),\n",
       " (('dilma',), 458),\n",
       " (('pt',), 438),\n",
       " (('corrupção',), 334),\n",
       " (('lula',), 322),\n",
       " (('justiça',), 290),\n",
       " (('direitos',), 288),\n",
       " (('trabalho',), 283),\n",
       " (('constituição',), 259),\n",
       " (('educação',), 255),\n",
       " (('crise',), 253),\n",
       " (('mulheres',), 249),\n",
       " (('economia',), 191),\n",
       " (('rio',), 187),\n",
       " (('crime',), 182),\n",
       " (('econômica',), 177),\n",
       " (('desenvolvimento',), 176),\n",
       " (('família',), 165)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo termos com 1 palavras\n",
    "stop_fivegrams = stop_quadgrams = stop_trigrams = stop_bigrams = []\n",
    "\n",
    "if fivegrams:\n",
    "    stop_fivegrams = list(list(zip(*fivegrams))[0])\n",
    "    \n",
    "if quadgrams:\n",
    "    stop_quadgrams = list(list(zip(*quadgrams))[0])\n",
    "\n",
    "if trigrams:\n",
    "    stop_trigrams = list(list(zip(*trigrams))[0])\n",
    "\n",
    "if bigrams:\n",
    "    stop_bigrams = list(list(zip(*bigrams))[0])\n",
    "\n",
    "onegram_tokens = clean_tokens(tokens, stop_fivegrams, stop_quadgrams, stop_trigrams, stop_bigrams,\n",
    "                             ONEGRAM_STOPWORDS)\n",
    "onegrams = ngrams_by_limit(onegram_tokens, 1, limit)\n",
    "onegrams[:20] # Os 20 primeiros onegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('impeachment',), 521),\n",
       " (('golpe',), 497),\n",
       " (('saúde',), 461),\n",
       " (('dilma',), 458),\n",
       " (('pt',), 438),\n",
       " (('corrupção',), 334),\n",
       " (('lula',), 322),\n",
       " (('justiça',), 290),\n",
       " (('direitos',), 288),\n",
       " (('trabalho',), 283),\n",
       " (('constituição',), 259),\n",
       " (('educação',), 255),\n",
       " (('crise',), 253),\n",
       " (('mulheres',), 249),\n",
       " (('michel', 'temer'), 202),\n",
       " (('dilma', 'rousseff'), 194),\n",
       " (('economia',), 191),\n",
       " (('rio',), 187),\n",
       " (('crime',), 182),\n",
       " (('econômica',), 177),\n",
       " (('desenvolvimento',), 176),\n",
       " (('eduardo', 'cunha'), 166),\n",
       " (('família',), 165),\n",
       " (('contas',), 157),\n",
       " (('segurança',), 153),\n",
       " (('presidência',), 151),\n",
       " (('brasília',), 146),\n",
       " (('josé',), 146),\n",
       " (('são', 'paulo'), 145),\n",
       " (('petrobras',), 139),\n",
       " (('parlamento',), 135),\n",
       " (('reforma',), 132),\n",
       " (('violência',), 129),\n",
       " (('supremo', 'tribunal', 'federal'), 129),\n",
       " (('servidores',), 127),\n",
       " (('pmdb',), 124),\n",
       " (('construção',), 123),\n",
       " (('eleitoral',), 120),\n",
       " (('psdb',), 120),\n",
       " (('golpista',), 118),\n",
       " (('agricultura',), 117),\n",
       " (('imprensa',), 116),\n",
       " (('maranhão',), 112),\n",
       " (('polícia',), 111),\n",
       " (('famílias',), 110),\n",
       " (('militar',), 109),\n",
       " (('sul',), 108),\n",
       " (('polícia', 'federal'), 108),\n",
       " (('distrito', 'federal'), 107),\n",
       " (('mercado',), 106),\n",
       " (('crimes',), 103),\n",
       " (('terra',), 103),\n",
       " (('bahia',), 102),\n",
       " (('eleição',), 101),\n",
       " (('carlos',), 101),\n",
       " (('eleições',), 100),\n",
       " (('democrático',), 99),\n",
       " (('renda',), 97),\n",
       " (('temer',), 95),\n",
       " (('ex-presidente',), 95),\n",
       " (('banco',), 95),\n",
       " (('juiz',), 94),\n",
       " (('tribunal',), 93),\n",
       " (('projetos',), 92),\n",
       " (('investimentos',), 92),\n",
       " (('ditadura',), 91),\n",
       " (('segurança', 'pública'), 91),\n",
       " (('luiz',), 90),\n",
       " (('água',), 89),\n",
       " (('pec',), 89),\n",
       " (('hospital',), 89),\n",
       " (('orçamento',), 88),\n",
       " (('fernando',), 88),\n",
       " (('senadores',), 88),\n",
       " (('aécio',), 86),\n",
       " (('produção',), 85),\n",
       " (('moro',), 85),\n",
       " (('crédito',), 85),\n",
       " (('joão',), 85),\n",
       " (('previdência',), 85),\n",
       " (('ética',), 84),\n",
       " (('obras',), 84),\n",
       " (('crime', 'responsabilidade'), 84),\n",
       " (('rio', 'grande', 'sul'), 84),\n",
       " (('petróleo',), 82),\n",
       " (('ex-presidente', 'lula'), 82),\n",
       " (('henrique',), 81),\n",
       " (('manifestação',), 80),\n",
       " (('dívida',), 80),\n",
       " (('desemprego',), 79),\n",
       " (('pernambuco',), 79),\n",
       " (('juros',), 78),\n",
       " (('sérgio',), 78),\n",
       " (('operação', 'lava-jato'), 78),\n",
       " (('democrática',), 77),\n",
       " (('psb',), 77),\n",
       " (('escola',), 76),\n",
       " (('crianças',), 76),\n",
       " (('tentativa',), 75),\n",
       " (('fatos',), 75),\n",
       " (('médicos',), 75)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tokens = onegrams + bigrams + trigrams + quadgrams + fivegrams\n",
    "result_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "result_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
